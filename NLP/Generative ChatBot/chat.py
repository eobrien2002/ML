import numpy as np
import re
from test_model import encoder_model, decoder_model, num_decoder_tokens, num_encoder_tokens, input_features_dict, target_features_dict, reverse_target_features_dict, max_decoder_seq_length, max_encoder_seq_length

class ChatBot:
  #These lines define class-level variables. negative_responses is a tuple of strings representing negative responses, 
  # and exit_commands is a tuple of strings representing exit commands. This allows the code to exit
  negative_responses = ("no", "nope", "nah", "naw", "not a chance", "sorry")

  exit_commands = ("quit", "pause", "exit", "goodbye", "bye", "later", "stop")
  

  #This method is used to initiate the chat. It prompts the user to start the chat with the chatbot, 
  # and if the response is a negative response, it exits the chat. If the response is positive, it starts the chat 
  # by calling the chat method with the response.
  def start_chat(self):
    user_response = input("Hi, I'm a chatbot trained on dialog from The Princess Bride. Would you like to chat with me?\n")
    
    if user_response in self.negative_responses:
      print("Ok, have a great day!\n")
      return
    
    self.chat(user_response)
  

  #This method takes an input string (reply), and continues the chat as long as make_exit returns False. 
  # The next reply from the user is obtained by calling input, and the chatbot's response is generated by calling generate_response.
  def chat(self, reply):
    while not self.make_exit(reply):
      reply = input(self.generate_response(reply))
    

  #This code defines a method string_to_matrix that takes in a string user_input and returns a matrix representation of the input.
  #The following method uses smoothing to account for words that are unknown to the model
  def string_to_matrix(self, user_input,eps=1e-6):

    #Use regular expression to find all alphanumeric and 
    # punctuation characters in the user_input string and store them in a list called tokens.
    tokens = re.findall(r"[\w']+|[^\s\w]", user_input)

    #Initialize an all-zero 3D numpy array of size (1, max_encoder_seq_length, num_encoder_tokens) 
    # and store it in user_input_matrix. The dtype is set to float32.
    user_input_matrix = np.zeros(
      (1, max_encoder_seq_length, num_encoder_tokens),
      dtype='float32')


    for timestep, token in enumerate(tokens):
      #Check if the current token is present in the input_features_dict dictionary.
      if token in input_features_dict:
        #If the current token is in input_features_dict, set the corresponding entry in the user_input_matrix array to 1.
        user_input_matrix[0, timestep, input_features_dict[token]] = 1.+ eps
      else:
        user_input_matrix[0, timestep, :] = eps
    return user_input_matrix
  

  #This method takes the encoded user input and uses the LTSM model to decode a response
  def generate_response(self, user_input):
    #This line of code calls the method string_to_matrix on the input string user_input 
    # and saves the result in the variable input_matrix
    input_matrix = self.string_to_matrix(user_input)

    #This line uses the encoder_model to generate the initial states for the decoder based on the input matrix 
    # created in step 1. The states are stored in the variable states_value
    states_value = encoder_model.predict(input_matrix)

    #This line creates an initial target sequence of zeros with shape (1, 1, num_decoder_tokens). 
    # The target sequence is used to generate predictions from the decoder.
    target_seq = np.zeros((1, 1, num_decoder_tokens))

    #This line sets the first token of the target sequence to be the start token, represented as <START>. 
    # The index of the start token in the target feature dictionary is obtained using the 
    target_seq[0, 0, target_features_dict['<START>']] = 1.
    
    chatbot_response = ''

    stop_condition = False
    while not stop_condition:

      #This line predicts the next token in the sequence using the decoder_model. The inputs to the model 
      # are the current target sequence and the current states. The output is a probability distribution over 
      # the possible next tokens, which is stored in output_tokens, and the updated hidden state and cell state, 
      # which are stored in hidden_state and cell_state, respectively.
      output_tokens, hidden_state, cell_state = decoder_model.predict(
        [target_seq] + states_value)
      
      #This line chooses the token with the highest probability from the output
      #tokens as the next token in the sequence. The index of the token is obtained using np.argmax.
      sampled_token_index = np.argmax(output_tokens[0, -1, :])

      #his line converts the index of the next token into the actual token by 
      # looking up the index in the reverse_target_features_dict dictionary.
      sampled_token = reverse_target_features_dict[sampled_token_index]
      
      chatbot_response += " " + sampled_token
      
      #checks whether the generated response has reached its maximum length or the end of the response has been reached.
      #If either of these conditions is true, the variable stop_condition is set to True which will end the while loop.
      if (sampled_token == '<END>' or len(chatbot_response) > max_decoder_seq_length):
        stop_condition = True
      
      #sets up a one-hot encoded matrix to represent the next input sequence to the decoder.
      target_seq = np.zeros((1, 1, num_decoder_tokens))

      #sets the value of the one-hot encoded matrix to represent the most likely next token based on the decoder's previous prediction.
      target_seq[0, 0, sampled_token_index] = 1.
      
      #updates the states of the decoder's LSTM to the values generated from the decoder's previous prediction.
      states_value = [hidden_state, cell_state]
      
    chatbot_response = chatbot_response.replace("<START>", "").replace("<END>", "\n")
      
    return chatbot_response
  

  #This method checks if the user response contains one of the exit commands. If it does it returns true which will break the loop in
  #the chat method
  def make_exit(self, reply):
    for exit_command in self.exit_commands:
      if exit_command in reply:
        print("Ok, have a great day!")
        return True
      
    return False

chatbot=ChatBot()

chatbot.start_chat()